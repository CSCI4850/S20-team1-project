% PACKAGES INCLUDED HERE 
% DO NOT NEED TO CHANGE
\documentclass[conference]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% TITLE GOES HERE

\title{Parking Lot Manager\\}


\author{\IEEEauthorblockN{Girgis Shihataa}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Middle Tennessee State University}\\
Murfreesboro, United States of America \\
grs2w@mtmail.mtsu.edu}
\and
\IEEEauthorblockN{William Smith}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Middle Tennessee State University}\\
Murfreesboro United States of America \\
wbs3d@mtmail.mtsu.edu}
\and
\IEEEauthorblockN{Michael Ketzner}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Middle Tennessee State University}\\
Murfreesboro, United States of America \\
mdk4g@mtmail.mtsu.edu}
\and
\IEEEauthorblockN{Justin Hill}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Middle Tennessee State University}\\
Murfreesboro, United States of America \\
jph5s@mtmail.mtsu.edu}
\and
\IEEEauthorblockN{Mubarek Mohammed}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Middle Tennessee State University}\\
Murfreesboro, United States of America \\
mmm9b@mtmail.mtsu.edu}
\and
\IEEEauthorblockN{Carolous Ghobrial}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Middle Tennessee State University}\\
Murfreesboro, United States of America \\
cag6p@mtmail.mtsu.edu}
}

\maketitle

% ABSTRACT 

\begin{abstract}
This document is a model and instructions for \LaTeX.
This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, 
or Math in Paper Title or Abstract.
\end{abstract}


% KEYWORDS

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

% INTRODUCTION SECTION
\section{Introduction}

If you are a student at MTSU, Middle Tennessee State University, and you commute, you know the struggles of finding a parking space near your class during the day. MTSU currently has a problem with parking lots for all the students who commute to campus. The number of students commuting to MTSU continues to increase every year and the problem has only increased. This always results in a large number of students funneling into and circling around parking lots at very desired locations on a daily basis. The parking lots can be completely full, but students will continue to drive around hoping they come across an empty spot. Our goal for this project was to build and train a neural network that can help provide a solution for this problem. 

Throughout the length of this project, we went through multiple ideas, or iterations, of the neural network. At first, we quickly recognized that for this project, we need a convolutional neural network \cite{b1}.

% BACKGROUND SECTION
\section{Background}

Start typing here \cite{b2}.

% METHODS SECTION
\section{Methods}

\subsection{Data}
We decided on using a prepared data-set available online that contains a total of 12584 images.The images have already been formatted in .JPG image format. The images were collected at varying weather conditions as well as different situations of light conditions. The difference in perspective and angles of view creates the capability to train the network with a variety of images.

\subsection{Input Processing}
We downsized the images to an input shape of 150X150 before feeding the images to the network. The image set has been divided into two batches, training and testing image data set. The training data set consists 11326 images. The testing data set consists 1258 images. We normalized the image from a scale of 0.0 to 255.0 to 0.0 to 1.0 float32 value. The normalization makes of the image data reduces the memory utilized. We utilized Keras image preprocessing tools to perform slight transformations on the image that helps in the creation of a stronger and more robust model. We performed preprocessing techniques including rotation range that performs
random rotation of the images, re-scaling factor to reduce the RGB value to range between 0.0 to 1.0, shear range alteration that cuts away part of the image that is deemed non-essential, stretching and fill mode that performs the reshaping of the image which entails the filling of the missing pixels with the nearest value of neighboring pixels (Fig 1). 
\begin{figure}[htbp]
\centerline{\includegraphics[width=\linewidth]{Figures/random_car_transform.jpg}}
\caption{Pre-processed image of a car.}
\label{fig}
\end{figure}

\subsection{Convolution Neural Networks}
For our neural network architecture, we built a Convolution Neural Network which have been known for providing a higher accuracy of recognition compared to other Neural Network architectures including YOLOv3. We built our network based on further research on well known CNN architectures including LeNet-5 which is designed for large-scale visual recognition problems. In comparison, our architectures is built to fit a smaller scale visual recognition where the solution is binary choice between parking space being empty or full. 

Our architecture accepts an input image shape of 150X150 with a number of channels equal to 3. Our architecture consists of three convolution layers that are essential to extract the visual features of the image. The filters selected for the first and second convolution layers is equal to 32. We increased the filters in the third convolution layer to 64 in order to grab the image features and patterns like corners and edges. We decided upon a kernel size of 3X3 in our layers which
aligns with the objective of capturing the images features.The convolution layers are followed by rectified linear unit activation function (ReLU) and max pooling layers with a pool size of 2X2. We flattened the 3D feature maps to 1D feature vectors. We pass the flatten layer to a dense layer consisting of 64 neurons followed by rectified linear unit activation function (ReLU). We chose a larger number of neuron size to improve the CNN architectures robustness and the ability to extract patterns. The dense layer is followed by another rectified linear unit activation function (ReLU). With the target of reducing over-fitting of the training data-set, we introduced the dropout layer that turns off 50 percent of the neurons randomly during training process. The final dense layer consists of a single neuron which is the representation of the solution of our network. A single neuron represents the fact of the outcome of the network as a 0 or 1 where 0 signals an image of a busy parking space while 1 represents an image of a free parking space. The model is compiled with binary crossentropy loss function which lines with the binary classification problem of our architecture. 
Figure 2 displays the detailed structure of our CNN.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=1]{Figures/model_plt.png}}
\caption{Detailed structure of the CNN.}
\label{fig}
\end{figure}

% RESULTS SECTION
\section{Results}

Start typing here \cite{b4}.

% DISCUSSION SECTION
\section{Discussion}

Start typing here \cite{b5}.

% REFERENCES
% THIS IS CREATED AUTOMATICALLY
\bibliographystyle{IEEEtran}
\bibliography{References} % change if another name is used for References file

\end{document}
